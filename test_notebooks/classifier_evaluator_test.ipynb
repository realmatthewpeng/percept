{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 20:54:36.617212: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MP/Desktop/WI25/CS291A/percept_project/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
    "\n",
    "# save the final model to file\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    " \n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    " \n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    " \n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9889 - loss: 0.0360\n",
      "> 99.170\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the deep model on the test dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    " \n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    " \n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# evaluate model on test dataset\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a new image.\n",
    "from numpy import argmax\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    " \n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "    test = pd.read_parquet(\"datasets/MNIST/test.parquet\")\n",
    "    image = Image.open(io.BytesIO(test[\"image\"].iloc[100]['bytes']))\n",
    "    img = np.array(image)\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "    # load model\n",
    "    model = load_model('final_model.h5')\n",
    "    # predict the class\n",
    "    predict_value = model.predict(img)\n",
    "    digit = argmax(predict_value)\n",
    "    print(digit)\n",
    " \n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1548da810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "test = pd.read_parquet(\"datasets/MNIST/test.parquet\")\n",
    "image = Image.open(io.BytesIO(test[\"image\"].iloc[100]['bytes']))\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
